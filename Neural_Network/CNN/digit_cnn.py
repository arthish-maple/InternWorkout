# -*- coding: utf-8 -*-
"""digit_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RFdEiiwzftvVtoRxzeFWEuvvX4TyOtT7
"""



import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from google.colab.patches import cv2_imshow
from PIL import Image
import tensorflow as tf
tf.random.set_seed(3)
from tensorflow import keras
from keras.datasets import mnist
from tensorflow.math import confusion_matrix

"""Loading the MNIST data from keras datasets"""

(x_train,y_train), (x_test,y_test) = mnist.load_data()

type(x_train)

# shape of numpy arrays
print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)

"""training data = 60,000 images

test data = 10,000 images

image dimension -> 28 x 28

Grayscale image -> 1 channel
"""

# Printing the 10th image

print(x_train[10])

print(x_train[10].shape)

# displaying the image

plt.imshow(x_train[25])
plt.show()

# print the corresponding label
print(y_train[25])

"""Image Lables"""

# unique values in y_train
print(np.unique(y_train))

# unique values in y_test
print(np.unique(y_test))

"""We can use these labels ass such or we can also apply one hot encoding

All the images have the Same dimension in this dataset, If not, we have to resize all the images to common dimension
"""

# scaling the values

x_train = x_train/255
x_test  = x_test/255

#printing the 10th image

print(x_train[10])

"""Building the Neural Network"""

# setting up the layers of the Neural Network

num_of_classes = 10

model = keras.Sequential()

model.add(keras.layers.Conv2D(32 , kernel_size = (3,3) , activation = 'relu' , input_shape = (28,28,1)))
model.add(keras.layers.MaxPooling2D(pool_size = (2,2)))

model.add(keras.layers.Conv2D(64 , kernel_size = (3,3) , activation = 'relu', input_shape = (28,28,1)))
model.add(keras.layers.MaxPooling2D(pool_size = (2,2)))

model.add(keras.layers.Flatten())

model.add(keras.layers.Dense(28, activation = 'relu'))
model.add(keras.layers.Dropout(0.5))

model.add(keras.layers.Dense(num_of_classes , activation = 'softmax'))

#compile the neural network

model.compile(optimizer = 'adam',
              loss = 'sparse_categorical_crossentropy',
              metrics = ['accuracy'])

#traing the model

history = model.fit(x_train , y_train , validation_split = 0.1 , epochs = 5)

loss , accuracy = model.evaluate(x_test , y_test)
print('test accuarcy ' , accuracy)

h = history

#plot loss and accuracy

plt.plot(h.history['loss'] , label = 'train loss')
plt.plot(h.history['val_loss'] , label = 'validation loss')
plt.legend()
plt.show()

plt.plot(h.history['accuracy'] , label = 'train accuracy')
plt.plot(h.history['val_accuracy'] , label = 'validation accuracy')
plt.legend()
plt.show()

# predictive system

input_image_path = input()

input_image = cv2.imread(input_image_path)

cv2_imshow(input_image)
grayscaleimg = cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)


input_image_resize = cv2.resize(grayscaleimg , (28,28))
input_image_scaled = input_image_resize/255

input_image_reshape = np.reshape(input_image_scaled , [1,28,28])

input_prediction = model.predict(input_image_reshape)

print(input_prediction)

input_pred_labels = np.argmax(input_prediction)

print(input_pred_labels)

# predictive system

input_image_path = input()

input_image = cv2.imread(input_image_path)
input_image.shape

grayscaleimg = cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)

grayscaleimg.shape